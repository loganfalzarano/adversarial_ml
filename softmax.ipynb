{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iters=1000, batch_size=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.batch_size = batch_size\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def softmax(self, logits):\n",
    "        exps = np.exp(logits)\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(np.unique(y))\n",
    "        y_hot = np.eye(num_classes)[y]\n",
    "\n",
    "        self.weights = np.random.randn(num_features, num_classes)\n",
    "        self.bias = np.zeros(num_classes)\n",
    "\n",
    "        for _ in range(self.num_iters):\n",
    "            # Mini-batch gradient descent\n",
    "            for i in range(0, num_samples, self.batch_size):\n",
    "                X_batch = X[i:i+self.batch_size]\n",
    "                y_batch = y_hot[i:i+self.batch_size]\n",
    "\n",
    "                scores = np.dot(X_batch, self.weights) + self.bias\n",
    "                probs = self.softmax(scores)\n",
    "\n",
    "                d_weights = np.dot(X_batch.T, (probs - y_batch)) / self.batch_size\n",
    "                d_bias = np.mean(probs - y_batch, axis=0)\n",
    "\n",
    "                self.weights -= self.learning_rate * d_weights\n",
    "                self.bias -= self.learning_rate * d_bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = np.dot(X, self.weights) + self.bias\n",
    "        probs = self.softmax(scores)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array of inputs of size [num_samples, num_features]\n",
    "        y: array of targets of size [num_samples]\n",
    "\n",
    "        Use trained model to compute predictions for given inputs. Use the provided labels to compute accuracy.\n",
    "        '''\n",
    "        scores = np.dot(X, self.weights) + self.bias\n",
    "        probs = self.softmax(scores)\n",
    "        return np.count_nonzero(np.argmax(probs, axis=1) == y) / len(y)\n",
    "    \n",
    "    def fgsm_adversarial_example(self, X, y, epsilon=0.1):\n",
    "        num_samples, _ = X.shape\n",
    "        adv_X = np.copy(X)\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            # Compute gradients of loss w.r.t. input\n",
    "            x = X[i:i+1, :]  # select one sample at a time\n",
    "            y_hot = np.zeros((1, self.weights.shape[1]))\n",
    "            y_hot[0, y[i]] = 1  # one-hot encoding of true label\n",
    "            scores = np.dot(x, self.weights) + self.bias\n",
    "            probs = self.softmax(scores)\n",
    "            loss = self.ce_loss(probs, y_hot)\n",
    "            grad = np.dot(self.weights, (probs - y_hot).T).T  # gradient w.r.t input\n",
    "\n",
    "            # Create adversarial example\n",
    "            adv_x = x + epsilon * np.sign(grad)\n",
    "            adv_x = np.clip(adv_x, 0, 1)  # Ensure the adversarial example remains within the valid input range\n",
    "            adv_X[i] = adv_x\n",
    "\n",
    "        return adv_X\n",
    "\n",
    "    def ce_loss(self, y_hat, y):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_hat: array of predicted probabilities of size [num_samples, num_classes]\n",
    "        y: array of true one-hot vectors of size [num_samples, num_classes]\n",
    "        '''\n",
    "        return -np.mean(y * np.log(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_train = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Prepare data for training\n",
    "X_train = mnist_train.data.numpy().reshape(-1, 28*28) / 255.0\n",
    "y_train = mnist_train.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9243\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = SoftmaxRegression(learning_rate=0.1, num_iters=1000, batch_size=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prepare data for testing\n",
    "X_test = mnist_test.data.numpy().reshape(-1, 28*28) / 255.0\n",
    "y_test = mnist_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.9243\n",
      "Adversarial Example Accuracy: 0.6719\n"
     ]
    }
   ],
   "source": [
    "adv_examples = model.fgsm_adversarial_example(X_test, y_test, epsilon=0.01)\n",
    "original_predictions = model.predict(X_test)\n",
    "adv_predictions = model.predict(adv_examples)\n",
    "original_accuracy = model.score(X_test, y_test)\n",
    "adv_accuracy = model.score(adv_examples, y_test)\n",
    "\n",
    "print(\"Original Accuracy:\", original_accuracy)\n",
    "print(\"Adversarial Example Accuracy:\", adv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see, the accuracy for the adversarial dataset is much lower. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
